{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrsZhhsVZY_j"
      },
      "source": [
        "<img src=\"./sharif.png\" alt=\"SUT logo\" width=300 height=300 align=left class=\"saturate\">\n",
        "\n",
        "<br>\n",
        "<font>\n",
        "<div dir=ltr align=center>\n",
        "<font color=0F5298 size=7>\n",
        "    Machine Learning <br>\n",
        "<font color=2565AE size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Spring 2024<br>\n",
        "<font color=3C99D size=5>\n",
        "    Practical Assignment 3<br>\n",
        "<font color=696880 size=4>\n",
        "    Ashkan Majidi - Shayan Salehi - Amirhossein Alamdar\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69mnuum6ZY_l"
      },
      "source": [
        "# Personal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMcgHAUTZY_l"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "student_number = '98100561'\n",
        "first_name = 'Soheil'\n",
        "last_name = 'Homayoonfard'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIp0hQUXZY_l"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this assignment, you will implement SVM (Support Vector Machines) for classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uVTW0IxZY_l"
      },
      "source": [
        "# Data Prepfocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4FXHAcIZY_l"
      },
      "source": [
        "Import your needed libraries in following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PCUya7YZY_l"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.2' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import cvxopt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVC\n",
        "from scipy.spatial import distance\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwtevaZiZY_m"
      },
      "source": [
        "Load data from ```satimage``` dataset and split data to features and labels. The ```label``` column is our target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7SQOQRXZY_m",
        "outputId": "9c93ae57-7353-4373-ec17-ea7c7c48dd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of features (X): (2134, 36)\n",
            "Shape of labels (y): (2134,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"satimage.csv\")\n",
        "data['label'].unique()\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "data = data[(data['label'] == 4) | (data['label'] == 6)]\n",
        "X = data.drop(['label'], axis=1).values\n",
        "y = data['label'].values\n",
        "\n",
        "# Check the shape of X and y\n",
        "print(\"Shape of features (X):\", X.shape)\n",
        "print(\"Shape of labels (y):\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzr-kKmAZY_m"
      },
      "source": [
        "Now split data to train, validation and test parts. 60% of data should be used for train, 15% for validation and 25% for test. After that scale the data to Standard Normal Distribution using ```StandardScaler``` class from ```scikit-learn``` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ituCD_phZY_m",
        "outputId": "c6a5f373-cf5f-498d-bba8-d2579dfd9b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train_scaled: (1280, 36)\n",
            "Shape of X_val_scaled: (320, 36)\n",
            "Shape of X_test_scaled: (534, 36)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.625)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.fit_transform(X_val)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# Check the shapes of the datasets after splitting and scaling\n",
        "print(\"Shape of X_train_scaled:\", X_train.shape)\n",
        "print(\"Shape of X_val_scaled:\", X_val.shape)\n",
        "print(\"Shape of X_test_scaled:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOIFo7NZZY_m"
      },
      "source": [
        "We want to train Binary SVM model for classification between labels 4 and 6. Choose corresponding datas and convert their lables to 1 and -1 respectively for 4 and 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ATQZApzZY_m",
        "outputId": "e5c9489e-b6d0-4858-c90e-d164bd3318d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of y_train_binary: (1280,)\n",
            "Shape of y_val_binary: (320,)\n",
            "Shape of y_test_binary: (534,)\n"
          ]
        }
      ],
      "source": [
        "# Convert labels 4 to 1 and 6 to -1\n",
        "y_train = np.where(y_train == 4, 1, -1)\n",
        "y_val = np.where(y_val == 4, 1, -1)\n",
        "y_test = np.where(y_test == 4, 1, -1)\n",
        "\n",
        "# Check the shapes of the binary datasets after filtering and converting labels\n",
        "print(\"Shape of y_train_binary:\", y_train.shape)\n",
        "print(\"Shape of y_val_binary:\", y_val.shape)\n",
        "print(\"Shape of y_test_binary:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heoy4lAjZY_m"
      },
      "source": [
        "# Model (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e40KGN-yZY_m"
      },
      "source": [
        "Here is soft margin svm convex optimization formulation.\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text { Minimize } & \\frac{1}{2}\\|\\mathbf{w}\\|^2+C \\sum_{i=1}^N \\xi_i \\\\\n",
        "\\text { Subject to } & y_i\\left(\\mathbf{w}^T \\mathbf{x}_i+b\\right) \\geq 1-\\xi_i, \\quad i=1,2, \\ldots, N \\\\\n",
        "& \\xi_i \\geq 0, \\quad i=1,2, \\ldots, N\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "write dual of the soft margin svm optimization problem below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfJv4ttPZY_n"
      },
      "source": [
        "$$\n",
        "\\text{Maximize}\\ \\ \\sum_{n=1}^{N}\\alpha_n-\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{m=1}^{N}\n",
        "\\alpha_n\\alpha_my^{(n)}y^{(m)}x^{{(n)}^T}x^{(m)}\n",
        "$$\n",
        "$$\n",
        "\\text{s.t.}\n",
        "\\begin{cases}\n",
        "    \\sum\\limits_{n=1}^{N}\\alpha_ny^{(n)}=0 \\\\\n",
        "    0\\leq\\alpha_n\\leq C & n=1,\\dots,N\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1bJ5elnZY_n"
      },
      "source": [
        "Now you should write this optimization problem in standard Quadratic Program (QP) form and use a QP solver to find optimal answer. Here is General form of a QP:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text { Minimize } & \\frac{1}{2} x^TPx + q^Tx + r \\\\\n",
        "\\text { Subject to } & Gx \\leq h \\\\\n",
        "& Ax = b\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Complete functions below and use ```cvxopt``` library which is a common library for solving QPs. Note that you can't use ```scikit-learn``` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tueClKa2ZY_n"
      },
      "outputs": [],
      "source": [
        "def soft_margin_svm(X, y, C):\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Gram matrix\n",
        "    K = np.dot(X, X.T)\n",
        "\n",
        "    # P, q, G, h, A, b matrices for cvxopt\n",
        "    P = cvxopt.matrix(np.outer(y, y) * K)\n",
        "    q = cvxopt.matrix(-np.ones(n_samples))\n",
        "    G = cvxopt.matrix(np.vstack((np.eye(n_samples) * -1, np.eye(n_samples))))\n",
        "    h = cvxopt.matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * C)))\n",
        "    A = cvxopt.matrix(y, (1, n_samples), 'd')\n",
        "    b = cvxopt.matrix(0.0)\n",
        "\n",
        "    # Solve QP problem\n",
        "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "    # Lagrange multipliers\n",
        "    alphas = np.array(solution['x']).flatten()\n",
        "\n",
        "    # Support vectors have non-zero lagrange multipliers\n",
        "    sv = (alphas > 1e-5)\n",
        "    ind = np.arange(len(alphas))[sv]\n",
        "    support_vectors = X[sv]\n",
        "    support_vector_labels = y[sv]\n",
        "    support_vector_alphas = alphas[sv]\n",
        "\n",
        "    return support_vectors, support_vector_labels, support_vector_alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eY61BRgZY_n",
        "outputId": "7a713004-d18a-4eab-ab23-7f144ff7c7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -6.0333e+02 -3.4454e+03  2e+04  3e+00  6e-13\n",
            " 1: -4.1178e+02 -2.3433e+03  3e+03  4e-01  5e-13\n",
            " 2: -3.7754e+02 -7.7981e+02  5e+02  3e-02  4e-13\n",
            " 3: -4.1948e+02 -5.4905e+02  1e+02  8e-03  4e-13\n",
            " 4: -4.3471e+02 -5.1686e+02  9e+01  4e-03  4e-13\n",
            " 5: -4.4565e+02 -4.9432e+02  5e+01  2e-03  3e-13\n",
            " 6: -4.5415e+02 -4.7739e+02  2e+01  6e-04  4e-13\n",
            " 7: -4.5821e+02 -4.7051e+02  1e+01  2e-04  4e-13\n",
            " 8: -4.6113e+02 -4.6592e+02  5e+00  6e-05  4e-13\n",
            " 9: -4.6247e+02 -4.6400e+02  2e+00  1e-05  4e-13\n",
            "10: -4.6293e+02 -4.6342e+02  5e-01  3e-06  4e-13\n",
            "11: -4.6306e+02 -4.6325e+02  2e-01  8e-07  4e-13\n",
            "12: -4.6313e+02 -4.6317e+02  5e-02  3e-14  5e-13\n",
            "13: -4.6315e+02 -4.6315e+02  8e-03  2e-14  4e-13\n",
            "14: -4.6315e+02 -4.6315e+02  4e-04  2e-14  4e-13\n",
            "Optimal solution found.\n"
          ]
        }
      ],
      "source": [
        "C = 1.0\n",
        "support_vectors, support_vector_labels, support_vector_alphas = soft_margin_svm(X_train, y_train, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Waw-VTE1ZY_o"
      },
      "outputs": [],
      "source": [
        "def predict_labels(x_test, support_vectors, support_vector_labels, support_vector_alphas):\n",
        "    # Calculate the kernel matrix between support vectors and test samples\n",
        "    K = np.dot(support_vectors, x_test.T)\n",
        "\n",
        "    # Calculate the decision function using the support vectors, their labels, and alphas\n",
        "    decision_func = np.dot((support_vector_labels * support_vector_alphas).reshape(1, -1), K)\n",
        "\n",
        "    # Predict the labels based on the sign of the decision function\n",
        "    y_pred = np.sign(decision_func).flatten()\n",
        "\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sV5VOQs_ZY_o"
      },
      "outputs": [],
      "source": [
        "y_pred = predict_labels(np.array(X_test), support_vectors, support_vector_labels, support_vector_alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw8NGr5QZY_o"
      },
      "source": [
        "# Evaluation (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZvzJj35ZY_p"
      },
      "source": [
        "Compute accuracy, balanced accuracy and plot confusion matrix of your trained model using ```Seaborn.heatmap()``` function. Use case of balanced accuracy is when dealing with imbalanced data, i.e. when one of the target classes appears a lot more than the other and it is defined by average of recall of classes. Confusion matrix is a $k\\times k$ (k is number of classes) matrix which cell ij is showing that number of data points labeld i which predicted j. For more detail of evaluation metrics you can see [here](https://neptune.ai/blog/balanced-accuracy).\n",
        "\n",
        "You may use ```scikit-learn``` library to compute these metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N7EsbkbkZY_p"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_test, y_pred):\n",
        "    # Calculate accuracy and balanced accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"Accuracy: \", accuracy)\n",
        "    print(\"Balanced Accuracy: \", balanced_accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
        "\n",
        "    return accuracy, balanced_accuracy, confusion_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7fbm6MfzSIO",
        "outputId": "ba22d2b3-56ee-4e87-eaa6-fcac760ecdcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7827715355805244\n",
            "Balanced Accuracy:  0.8286458333333333\n",
            "Confusion Matrix:\n",
            " [[278 106]\n",
            " [ 10 140]]\n"
          ]
        }
      ],
      "source": [
        "_, _, confusion_mat = evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "m01wWVIPZY_p",
        "outputId": "19087a9c-a963-4931-9135-e5a640cb7c56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm_matrix = pd.DataFrame(data=confusion_mat, columns=['Predict Negative:-1', 'Predict Positive:1'],\n",
        "                                 index=['Actual Negative:-1', 'Actual Positive:1'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='mako')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTYgsAj6ZY_p"
      },
      "source": [
        "# Fine-tunning (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7wR-rZhZY_p"
      },
      "source": [
        "like what you did before, implement Soft Margin SVM but now use rbf kernel. To determine rbf $\\gamma$ parameter use validation datas and find best(best by balanced accuracy) $\\gamma$ between 0.001 , 0.01, 1, 10, 100. Not that you can't use ```scikit-learn``` library here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KAZHPrqSZY_p"
      },
      "outputs": [],
      "source": [
        "def rbf(x1, x2, gamma=1):\n",
        "    \"\"\"Compute the Radial Basis Function (RBF) kernel between two vectors.\"\"\"\n",
        "    diff = np.subtract(x1, x2)\n",
        "    squared_norm = np.dot(diff, diff)\n",
        "    return np.exp(-gamma * squared_norm)\n",
        "\n",
        "def soft_margin_svm(X, y, C, gamma=1):\n",
        "    \"\"\"Train a soft-margin Support Vector Machine (SVM) using the RBF kernel.\"\"\"\n",
        "    n = X.shape[0]\n",
        "\n",
        "    # Compute the RBF kernel matrix\n",
        "    K = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            K[i, j] = rbf(X[i], X[j], gamma)\n",
        "\n",
        "    # Define the optimization problem\n",
        "    P = cvxopt.matrix(np.outer(y, y) * K)\n",
        "    q = cvxopt.matrix(-np.ones(n))\n",
        "    G = cvxopt.matrix(np.vstack((-np.eye(n), np.eye(n))))\n",
        "    h = cvxopt.matrix(np.hstack((np.zeros(n), C * np.ones(n))))\n",
        "    A = cvxopt.matrix(y, (1, n), 'd')\n",
        "    b = cvxopt.matrix(0.0)\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "    alphas = np.ravel(solution['x'])\n",
        "\n",
        "    # Extract support vectors, their labels, and corresponding alphas\n",
        "    sv = (alphas > 1e-5)\n",
        "    support_vectors = X[sv]\n",
        "    support_vector_labels = y[sv]\n",
        "    support_vector_alphas = alphas[sv]\n",
        "\n",
        "    return support_vectors, support_vector_labels, support_vector_alphas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv2k640YZY_p",
        "outputId": "3cd1bd3f-afc9-4267-acfd-f9a7ded768cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -4.6159e+02 -3.1383e+03  2e+04  3e+00  1e-14\n",
            " 1: -3.2679e+02 -1.9760e+03  2e+03  2e-01  8e-15\n",
            " 2: -3.4110e+02 -6.4505e+02  3e+02  2e-02  7e-15\n",
            " 3: -3.8469e+02 -4.9276e+02  1e+02  6e-03  7e-15\n",
            " 4: -4.0190e+02 -4.5422e+02  5e+01  2e-03  8e-15\n",
            " 5: -4.0999e+02 -4.3762e+02  3e+01  9e-04  7e-15\n",
            " 6: -4.1706e+02 -4.2408e+02  7e+00  2e-04  8e-15\n",
            " 7: -4.1889e+02 -4.2104e+02  2e+00  3e-05  8e-15\n",
            " 8: -4.1971e+02 -4.1989e+02  2e-01  2e-06  8e-15\n",
            " 9: -4.1979e+02 -4.1980e+02  1e-02  9e-08  8e-15\n",
            "10: -4.1979e+02 -4.1979e+02  2e-04  2e-09  9e-15\n",
            "Optimal solution found.\n",
            "Accuracy:  0.796875\n",
            "Balanced Accuracy:  0.8309601960149785\n",
            "Confusion Matrix:\n",
            " [[166  57]\n",
            " [  8  89]]\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.4464e+02 -2.5255e+03  1e+04  2e+00  2e-15\n",
            " 1: -1.9884e+02 -1.4271e+03  1e+03  1e-01  1e-15\n",
            " 2: -2.1675e+02 -4.4274e+02  2e+02  2e-02  1e-15\n",
            " 3: -2.4005e+02 -3.0562e+02  7e+01  2e-03  1e-15\n",
            " 4: -2.4925e+02 -2.6917e+02  2e+01  4e-04  1e-15\n",
            " 5: -2.5237e+02 -2.5832e+02  6e+00  7e-05  2e-15\n",
            " 6: -2.5316e+02 -2.5618e+02  3e+00  3e-15  2e-15\n",
            " 7: -2.5369e+02 -2.5472e+02  1e+00  6e-15  2e-15\n",
            " 8: -2.5389e+02 -2.5423e+02  3e-01  7e-15  1e-15\n",
            " 9: -2.5398e+02 -2.5402e+02  4e-02  2e-14  2e-15\n",
            "10: -2.5399e+02 -2.5399e+02  1e-03  6e-15  2e-15\n",
            "11: -2.5399e+02 -2.5399e+02  1e-05  7e-15  2e-15\n",
            "Optimal solution found.\n",
            "Accuracy:  0.8\n",
            "Balanced Accuracy:  0.8273773750635662\n",
            "Confusion Matrix:\n",
            " [[169  54]\n",
            " [ 10  87]]\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -4.2495e+02 -2.1643e+03  2e+03  2e-13  1e-15\n",
            " 1: -4.3381e+02 -5.5966e+02  1e+02  1e-14  5e-16\n",
            " 2: -4.4446e+02 -4.5299e+02  9e+00  1e-14  2e-16\n",
            " 3: -4.4563e+02 -4.4600e+02  4e-01  1e-14  2e-16\n",
            " 4: -4.4571e+02 -4.4572e+02  1e-02  4e-15  2e-16\n",
            " 5: -4.4571e+02 -4.4571e+02  4e-04  1e-14  2e-16\n",
            "Optimal solution found.\n",
            "Accuracy:  0.8\n",
            "Balanced Accuracy:  0.8273773750635662\n",
            "Confusion Matrix:\n",
            " [[169  54]\n",
            " [ 10  87]]\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -4.7428e+02 -2.1499e+03  2e+03  6e-13  4e-16\n",
            " 1: -4.8187e+02 -5.2117e+02  4e+01  9e-14  2e-16\n",
            " 2: -4.8871e+02 -4.8914e+02  4e-01  1e-15  1e-16\n",
            " 3: -4.8879e+02 -4.8879e+02  4e-03  2e-14  8e-17\n",
            " 4: -4.8879e+02 -4.8879e+02  4e-05  2e-15  2e-16\n",
            "Optimal solution found.\n",
            "Accuracy:  0.8\n",
            "Balanced Accuracy:  0.8273773750635662\n",
            "Confusion Matrix:\n",
            " [[169  54]\n",
            " [ 10  87]]\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -4.7428e+02 -2.1499e+03  2e+03  7e-13  4e-16\n",
            " 1: -4.8187e+02 -5.2117e+02  4e+01  7e-14  3e-16\n",
            " 2: -4.8871e+02 -4.8914e+02  4e-01  6e-14  8e-17\n",
            " 3: -4.8879e+02 -4.8879e+02  4e-03  2e-14  7e-17\n",
            " 4: -4.8879e+02 -4.8879e+02  4e-05  9e-15  1e-16\n",
            "Optimal solution found.\n",
            "Accuracy:  0.8\n",
            "Balanced Accuracy:  0.8273773750635662\n",
            "Confusion Matrix:\n",
            " [[169  54]\n",
            " [ 10  87]]\n",
            "Best gamma: 0.01\n"
          ]
        }
      ],
      "source": [
        "# Define the list of gamma values to explore\n",
        "gammas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Initialize variables to store the best model's parameters\n",
        "best_gamma = None\n",
        "best_balanced_accuracy = -1\n",
        "best_support_vectors = None\n",
        "best_support_vector_labels = None\n",
        "best_support_vector_alphas = None\n",
        "\n",
        "# Loop over each gamma value\n",
        "for gamma in gammas:\n",
        "    # Train a soft-margin SVM using the current gamma value\n",
        "    support_vectors, support_vector_labels, support_vector_alphas = soft_margin_svm(X_train, y_train, C, gamma)\n",
        "\n",
        "    # Predict labels for the validation set\n",
        "    y_pred = predict_labels(np.array(X_val), support_vectors, support_vector_labels, support_vector_alphas)\n",
        "\n",
        "    # Evaluate the model's performance on the validation set\n",
        "    _, ba1, _ = evaluate(y_val, y_pred)\n",
        "\n",
        "    # Update the best model's parameters if the current model has a higher balanced accuracy\n",
        "    if ba1 > best_balanced_accuracy:\n",
        "        best_gamma = gamma\n",
        "        best_balanced_accuracy = ba1\n",
        "        best_support_vectors = support_vectors\n",
        "        best_support_vector_labels = support_vector_labels\n",
        "        best_support_vector_alphas = support_vector_alphas\n",
        "\n",
        "# Print the best gamma value\n",
        "print(\"Best gamma:\", best_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7-6EuwRZY_p",
        "outputId": "497c528a-0d4d-44eb-e3a9-778f7d7b2ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7846441947565543\n",
            "Balanced Accuracy:  0.8360416666666667\n",
            "Confusion Matrix:\n",
            " [[276 108]\n",
            " [  7 143]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = predict_labels(np.array(X_test), best_support_vectors, best_support_vector_labels, best_support_vector_alphas)\n",
        "_, _, confusion_mat = evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omrKDEcQZY_q"
      },
      "source": [
        "# Multiclass SVM (30 points + 50 points optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3nMZP9kZY_q"
      },
      "source": [
        "Now we want implement Multiclass SVM. Use ```SVC``` function with rbf kernel from ```scikit-learn``` package on all train datas (all six classes) and choose best hyperparameters for $C$ and $\\gamma$ between 0.01, 0.1, 1, 10, 100. After that evaluate it with your function.\n",
        "\n",
        "Note that in this example we had enough data to split them in train and validation but in case that we don't have enough data, ```scikit-learn``` has a built-in fast library named ```GridSearchCV()``` which can help us in hyperparameter tunning with cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "az23apgYpLB7"
      },
      "outputs": [],
      "source": [
        "# Load the dataset from CSV file\n",
        "data = pd.read_csv('satimage.csv')\n",
        "\n",
        "# Extract features (X) and target labels (y)\n",
        "X = data.drop(['label'], axis=1).values\n",
        "y = data['label'].values\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.625)\n",
        "\n",
        "# Standardize features using scaler (assuming 'scaler' is already defined)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.fit_transform(X_val)\n",
        "X_test = scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nvQ8AW93ZY_q"
      },
      "outputs": [],
      "source": [
        "Cs = [0.01, 0.1, 1, 10, 100]\n",
        "gammas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    \"\"\"Evaluate the performance of a classifier.\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
        "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
        "    return accuracy, balanced_accuracy, confusion_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqYRJU2H8wZv",
        "outputId": "1f64b3c6-d835-4aa5-c2d3-44323b9d93c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best C: 10\n",
            "Best Gamma: 0.1\n",
            "Accuracy: 0.9129894344313239\n",
            "Balanced Accuracy: 0.8913489179849763\n",
            "Confusion Matrix:\n",
            " [[358   0   2   0   1   0]\n",
            " [  0 175   0   0   5   1]\n",
            " [  5   3 337  13   0   8]\n",
            " [  0   3  32  90   3  13]\n",
            " [  1   2   2   2 166   5]\n",
            " [  0   0   5  27   7 343]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.9129894344313239,\n",
              " 0.8913489179849763,\n",
              " array([[358,   0,   2,   0,   1,   0],\n",
              "        [  0, 175,   0,   0,   5,   1],\n",
              "        [  5,   3, 337,  13,   0,   8],\n",
              "        [  0,   3,  32,  90,   3,  13],\n",
              "        [  1,   2,   2,   2, 166,   5],\n",
              "        [  0,   0,   5,  27,   7, 343]]))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the parameter grid\n",
        "param_grid = {'C': Cs, 'gamma': gammas}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Train the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_gamma = grid_search.best_params_['gamma']\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best C:\", best_C)\n",
        "print(\"Best Gamma:\", best_gamma)\n",
        "\n",
        "# Predict labels on test data using the model with best hyperparameters\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lRPhte8ZY_q"
      },
      "source": [
        "Implement Multiclass SVM from scratch without using ready functions (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fnr15qZkZY_q"
      },
      "outputs": [],
      "source": [
        "class SVM:\n",
        "    # Define kernel functions as lambda functions\n",
        "    linear = lambda x, x_, c=0: x @ x_.T\n",
        "    polynomial = lambda x, x_, Q=5: (1 + x @ x_.T)**Q\n",
        "    rbf = lambda x, x_, gamma=10: np.exp(-gamma * distance.cdist(x, x_,'sqeuclidean'))\n",
        "\n",
        "    # Dictionary to map kernel names to kernel functions\n",
        "    kernel_funs = {'linear': linear, 'polynomial': polynomial, 'rbf': rbf}\n",
        "\n",
        "    def __init__(self, kernel='rbf', C=1, k=2):\n",
        "        \"\"\"Initialize the SVM model with hyperparameters.\"\"\"\n",
        "        # Set the hyperparameters\n",
        "        self.kernel_str = kernel\n",
        "        self.kernel = SVM.kernel_funs[kernel]  # Select kernel function based on the kernel name\n",
        "        self.C = C  # Regularization parameter\n",
        "        self.k = k  # Number of classes for multi-class classification\n",
        "\n",
        "        # Training data and support vectors\n",
        "        self.X, self.y = None, None  # Training data\n",
        "        self.alphas = None  # Lagrange multipliers\n",
        "\n",
        "        # For multi-class classification\n",
        "        self.multiclass = False  # Flag to indicate multi-class classification\n",
        "        self.clfs = []  # List to store binary classifiers for multi-class\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the SVM model to the training data.\"\"\"\n",
        "        # Multi-class classification\n",
        "        if len(np.unique(y)) > 2:\n",
        "            self.multiclass = True\n",
        "            return self.multi_fit(X, y)\n",
        "\n",
        "        # Relabel if needed\n",
        "        if set(np.unique(y)) == {0, 1}:\n",
        "            y[y == 0] = -1\n",
        "\n",
        "        # Ensure y has dimensions Nx1\n",
        "        self.y = y.reshape(-1, 1).astype(np.double)\n",
        "        self.X = X\n",
        "        N = X.shape[0]\n",
        "\n",
        "        # Compute the kernel matrix over all possible pairs of (x, x') in the data\n",
        "        self.K = self.kernel(X, X, self.k)\n",
        "\n",
        "        # Define the optimization problem\n",
        "        P = cvxopt.matrix(self.y @ self.y.T * self.K)\n",
        "        q = cvxopt.matrix(-np.ones((N, 1)))\n",
        "        A = cvxopt.matrix(self.y.T)\n",
        "        b = cvxopt.matrix(np.zeros(1))\n",
        "        G = cvxopt.matrix(np.vstack((-np.identity(N), np.identity(N))))\n",
        "        h = cvxopt.matrix(np.vstack((np.zeros((N,1)), np.ones((N,1)) * self.C)))\n",
        "\n",
        "        # Solve the optimization problem\n",
        "        cvxopt.solvers.options['show_progress'] = False\n",
        "        sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
        "        self.alphas = np.array(sol[\"x\"])\n",
        "\n",
        "        # Map support vectors\n",
        "        self.is_sv = ((self.alphas > 1e-3) & (self.alphas <= self.C)).squeeze()\n",
        "        self.margin_sv = np.argmax((1e-3 < self.alphas) & (self.alphas < self.C - 1e-3))\n",
        "\n",
        "    def multi_fit(self, X, y):\n",
        "        \"\"\"Fit the SVM model for multi-class classification.\"\"\"\n",
        "        self.k = len(np.unique(y))\n",
        "        for i in range(self.k):\n",
        "            Xs, Ys = X, copy.copy(y)\n",
        "            Ys[Ys!=i], Ys[Ys==i] = -1, +1\n",
        "            clf = SVM(kernel=self.kernel_str, C=self.C, k=self.k)\n",
        "            clf.fit(Xs, Ys)\n",
        "            self.clfs.append(clf)\n",
        "\n",
        "    def predict(self, X_t):\n",
        "        \"\"\"Predict labels for test data.\"\"\"\n",
        "        if self.multiclass:\n",
        "            return self.multi_predict(X_t)\n",
        "\n",
        "        xₛ, yₛ = self.X[self.margin_sv, np.newaxis], self.y[self.margin_sv]\n",
        "        alphas, y, X= self.alphas[self.is_sv], self.y[self.is_sv], self.X[self.is_sv]\n",
        "\n",
        "        b = yₛ - np.sum(alphas * y * self.kernel(X, xₛ, self.k), axis=0)\n",
        "        score = np.sum(alphas * y * self.kernel(X, X_t, self.k), axis=0) + b\n",
        "        return np.sign(score).astype(int), score\n",
        "\n",
        "    def multi_predict(self, X):\n",
        "        \"\"\"Predict labels for test data in multi-class setting.\"\"\"\n",
        "        preds = np.zeros((X.shape[0], self.k))\n",
        "        for i, clf in enumerate(self.clfs):\n",
        "            _, preds[:, i] = clf.predict(X)\n",
        "        return np.argmax(preds, axis=1)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"Evaluate the performance of the SVM model.\"\"\"\n",
        "        outputs, _ = self.predict(X)\n",
        "        accuracy = np.sum(outputs == y) / len(y)\n",
        "        return round(accuracy, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcgkVjpKpypT",
        "outputId": "b836a3d7-e691-48e8-eac9-b5426f71cd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.22995649471721566\n",
            "Balanced Accuracy: 0.17076502732240437\n",
            "Confusion Matrix:\n",
            " [[361   0   0   0   0   0]\n",
            " [181   0   0   0   0   0]\n",
            " [357   0   9   0   0   0]\n",
            " [140   0   1   0   0   0]\n",
            " [178   0   0   0   0   0]\n",
            " [382   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize an SVM object with k=6 for multi-class classification\n",
        "my_svm = SVM(k=6)\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "my_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test data using multi-class prediction\n",
        "y_pred = my_svm.multi_predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYnVGaccZY_q"
      },
      "source": [
        "# Different SVM Kernels (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTvKdwCiZY_q"
      },
      "source": [
        "A kernel in SVM is like a tool that helps solve tricky problems. It lets us work in a space with many dimensions, making complex calculations easier. With kernels, we can deal with lots of dimensions, even an endless amount. Kernels are crucial for sorting data into groups and help spot patterns in the data we're looking at. They're especially good at tackling twisty problems with a straightforward approach.\n",
        "\n",
        "Sometimes, finding a straight line or flat surface to divide data isn't possible, especially as we explore more dimensions. That's where different types of SVM kernels come in handy. They transform twisty, complicated data into a simpler form that's easier to separate. In this explanation, we talk about 4 popular types of these kernels. Also in following cells you can use any package.\n",
        "\n",
        "<img src=\"./kernel.jpg\" alt=\"Types of Kernel Functions\"  align=center class=\"saturate\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldkfR-8rZY_q"
      },
      "source": [
        "### Linear Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c45-8aKZY_q"
      },
      "source": [
        "This is the simplest kind of kernel, typically working in one dimension. It works best when dealing with a lot of features. Linear kernels are quicker than other types.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$F(x, x_j) = sum(x, x_j)$$\n",
        "\n",
        "Now Implement svc classifier using a linear kernel. Get the prediction and evaluate it by function which you implemented before. Also plot confusion matrix by `Seaborn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ7auDVFZY_r",
        "outputId": "b87eff49-83f8-4d1d-9f19-b582a3ecad1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8669981354878806\n",
            "Balanced Accuracy: 0.8295360951576113\n",
            "Confusion Matrix:\n",
            " [[358   0   2   0   1   0]\n",
            " [  1 167   0   0  13   0]\n",
            " [  4   0 338  22   0   2]\n",
            " [  0   1  35  71   4  30]\n",
            " [  5   5   0   4 143  21]\n",
            " [  0   0   5  44  15 318]]\n"
          ]
        }
      ],
      "source": [
        "C = 10  # Set the value of C\n",
        "\n",
        "# Initialize a linear SVM classifier with the specified C value\n",
        "svc_linear = SVC(kernel='linear', C=C)\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svc_linear.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test data\n",
        "y_pred = svc_linear.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model using the evaluate function\n",
        "_, _, confusion_mat = evaluate(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A21ssbwbZY_r"
      },
      "source": [
        "### Gaussian RBF kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EW_XkaqZY_r"
      },
      "source": [
        "This kernel is a favorite choice in SVM, especially for data that doesn't line up straight. It's great for sorting data when you don't know much about it beforehand.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$F(x, x_j) = \\exp{(-\\gamma ||x - xj||^2)}$$\n",
        "\n",
        "Now, configure the SVC classifier with a sigmoid kernel. Get the prediction and evaluate it by function which you implemented before. Also plot confusion matrix as previous part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjQFTrqiZY_r",
        "outputId": "49e02950-9faf-4b98-b96b-7774cdf476c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9129894344313239\n",
            "Balanced Accuracy: 0.8913489179849763\n",
            "Confusion Matrix:\n",
            " [[358   0   2   0   1   0]\n",
            " [  0 175   0   0   5   1]\n",
            " [  5   3 337  13   0   8]\n",
            " [  0   3  32  90   3  13]\n",
            " [  1   2   2   2 166   5]\n",
            " [  0   0   5  27   7 343]]\n"
          ]
        }
      ],
      "source": [
        "C = 10  # Set the value of C\n",
        "gamma = 0.1  # Set the value of gamma\n",
        "\n",
        "# Initialize an SVM classifier with RBF kernel, specified C, and gamma values\n",
        "svc_rbf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svc_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test data\n",
        "y_pred = svc_rbf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model using the evaluate function\n",
        "_, _, confusion_mat = evaluate(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE4flRq_ZY_r"
      },
      "source": [
        "### Polynomial Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5niW3yI6ZY_r"
      },
      "source": [
        "This is a broader version of the linear kernel. It's not as popular because it's not as quick or precise.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$F(x, x_j) = (x.x_j+1)^d$$\n",
        "\n",
        "Now, set up the SVC classifier using a *polynomial* kernel. Get the prediction and evaluate it by function which you implemented before. Also plot confusion matrix as previous parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8FvJa-TZY_r",
        "outputId": "c5561bfd-abcb-4057-ea5c-5d0dbb92d09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.889372280919826\n",
            "Balanced Accuracy: 0.8728750664413464\n",
            "Confusion Matrix:\n",
            " [[357   0   2   0   2   0]\n",
            " [  1 172   0   2   6   0]\n",
            " [  9   0 329  18   0  10]\n",
            " [  1   3  29  93   2  13]\n",
            " [  1   1   1   2 161  12]\n",
            " [  0   1   6  46  10 319]]\n"
          ]
        }
      ],
      "source": [
        "C = 10  # Set the value of C\n",
        "degree = 6  # Set the degree of the polynomial kernel\n",
        "coef0 = 1  # Set the coefficient for the polynomial kernel\n",
        "\n",
        "# Initialize an SVM classifier with polynomial kernel, specified C, degree, and coef0 values\n",
        "svc_poly = SVC(kernel='poly', C=C, degree=degree, coef0=coef0)\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svc_poly.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test data\n",
        "y_pred = svc_poly.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model using the evaluate function\n",
        "_, _, confusion_mat = evaluate(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lP9P9Y1ZY_r"
      },
      "source": [
        "### Sigmoid Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_N6UDcJZY_r"
      },
      "source": [
        "This is mainly chosen for use with neural networks. The kernel function acts like the activation function in a two-layer perceptron neural network model, helping to activate the neurons.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "$$F(x, x_j) = \\tanh(α x a y + c)$$\n",
        "\n",
        "Now, configure the SVC classifier with a sigmoid kernel. Get the prediction and evaluate it by function which you implemented before. Also plot confusion matrix as previous parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO6r8fP1ZY_s",
        "outputId": "719a1a14-257a-4b0e-fe94-b0dbf2872344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4133001864512119\n",
            "Balanced Accuracy: 0.31317339299386615\n",
            "Confusion Matrix:\n",
            " [[264  43  46   0   0   8]\n",
            " [154  20   1   0   1   5]\n",
            " [151   1 191  17   0   6]\n",
            " [ 22   1  44   0   2  72]\n",
            " [ 19  51   7   2   6  93]\n",
            " [ 26   4  15 149   4 184]]\n"
          ]
        }
      ],
      "source": [
        "C = 10  # Set the value of C\n",
        "gamma = 1  # Set the value of gamma for the sigmoid kernel\n",
        "coef0 = 0  # Set the value of coef0 for the sigmoid kernel\n",
        "\n",
        "# Initialize an SVM classifier with sigmoid kernel, specified C, gamma, and coef0 values\n",
        "svc_sigmoid = SVC(kernel='sigmoid', C=C, gamma=gamma, coef0=coef0)\n",
        "\n",
        "# Fit the SVM model to the training data\n",
        "svc_sigmoid.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the test data\n",
        "y_pred = svc_sigmoid.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model using the evaluate function\n",
        "_, _, confusion_mat = evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdUJOiBjZY_s"
      },
      "source": [
        "Compare these four kernel functions with each other. What are the main advantages and disadvantages of each one?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8eAueWbZY_s"
      },
      "source": [
        "\n",
        "\n",
        "# Linear Kernel:\n",
        "\n",
        "**Advantages**\n",
        "- Computationally efficient, especially with large datasets.\n",
        "- Works well when the data is linearly separable.\n",
        "- Fewer hyperparameters to tune.\n",
        "\n",
        "\n",
        "**Disadvantages**\n",
        "- Limited capacity to capture complex relationships in the data.\n",
        "- Performs poorly when the data is non-linearly separable.\n",
        "\n",
        "# RBF Kernel:\n",
        "\n",
        "**Advantages**\n",
        "- Highly flexible, capable of capturing complex relationships in the data.\n",
        "- Effective in high-dimensional spaces.\n",
        "- Suitable for both linear and non-linear data.\n",
        "\n",
        "\n",
        "**Disadvantages**\n",
        "- Computationally expensive, especially with large datasets.\n",
        "- Sensitive to the choice of hyperparameters, such as the width (gamma) parameter.\n",
        "- Prone to overfitting, especially with noisy data.\n",
        "\n",
        "\n",
        "\n",
        "# Polynomial Kernel:\n",
        "\n",
        "**Advantages**\n",
        "- Capable of capturing complex, non-linear relationships in the data.\n",
        "- Can be computationally efficient for lower degrees.\n",
        "\n",
        "\n",
        "**Disadvantages**\n",
        "- Sensitive to the choice of hyperparameters, such as the degree of the polynomial.\n",
        "- Computationally expensive, especially with higher degrees.\n",
        "- Prone to overfitting, especially with high-degree polynomials.\n",
        "\n",
        "# Sigmoid Kernel:\n",
        "\n",
        "\n",
        "**Advantages**\n",
        "- Can capture non-linear relationships, especially if the data has a sigmoidal shape.\n",
        "- Can be computationally efficient.\n",
        "\n",
        "\n",
        "**Disadvantages**\n",
        "- Sensitive to the choice of hyperparameters, such as the coefficients and intercept.\n",
        "- Prone to poor performance if hyperparameters are not properly tuned.\n",
        "Less commonly used compared to other kernels due to its specific shape requirements."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "69mnuum6ZY_l"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
